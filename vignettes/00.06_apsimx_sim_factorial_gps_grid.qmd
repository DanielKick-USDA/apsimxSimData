---
title: "00.06_apsimx_sim_factorial_gps_grid"
format: html
editor: source
---

This file is basically a repeat of 00.04 but uses what I learned from that file and from 00.05 to speed up computation by using apsimx to run the factorials for each site rather than calling apsimx once per condition set.

```{r}
library(tidyverse)
library(apsimx)

if (!str_detect(osVersion, 'Ubuntu')){
  apsimx_options(exe.path = 'C:\\Users\\drk8b9\\AppData\\Local\\Programs\\APSIM2023.5.7219.0\\bin\\ApsimNG.exe')
  apsimx_options(examples.path = 'C:\\Users\\drk8b9\\AppData\\Local\\Programs\\APSIM2023.5.7219.0\\Examples')
}

require(soilDB)
require(sp)
require(sf)
require(spData)
require(DBI)

devtools::load_all()
if (!str_detect(getwd(), '/vignettes$')){setwd(paste0(getwd(), '/vignettes'))}
```

```{r}
cache_path <- '../data/00.06_apsimx_sim_factorial_gps_grid/'
ensure_dir_path_exists(dir_path = cache_path)
```

## Setup for APSIMX template file.

Many cultivars
```{r cultivars tested}
# [Field].Sow on a fixed date.Script.CultivarName = A_80, A_90, A_95, A_100, A_103, A_105, A_108, A_110, A_112, A_115, A_120, A_130, Atrium, B_80, B_90, B_95, B_100, B_103, B_105, B_108, B_110, B_112, B_115, B_120, B_130, CG4141, GH_5009, GH_5019WX, HY_110, Hycorn_40, Hycorn_53, Katumani, Laila, LY_110, Makueni, malawi_local, Melkassa, mh12, mh16, mh17, mh18, mh19, NSCM_41, P1197, Pioneer_3153, Pioneer_33M54, Pioneer_34K77, Pioneer_38H20, Pioneer_39G12, Pioneer_39V43, r201, r215, sc401, sc501, sc601, sc623, sc625, sr52

```

Varying planting days
```{r}
planting_dates <- data.frame(
  expand.grid(
    years = 2000, # instead of including a leap year and non-leap year 
                  # I only use one year and sample more heavily. Otherwise there
                  # would be doublets with larger gaps.
    doy = seq(50, 170, by = 4) 
    )
  )


planting_dates$planting_date <- as.Date(planting_dates$doy, 
                                        origin = paste0(planting_dates$year, '-01-01'))
# convert to day-month format
planting_dates$planting_date <- unlist(
  map(str_split(planting_dates$planting_date, '-'), function(e){
    paste0(e[3], '-', month.abb[as.numeric(e[2])])
}))

# string for apsimx
paste(unique(planting_dates$planting_date), collapse = ', ' )
```




## Parse Soils.apsimx
```{r}
# Find all the soil models in the apsimx file that are in 
temp <- jsonlite::read_json("../inst/extdata/Soils.apsimx")

soils_list <- list()

state_n <- length(temp$Children[[2]]$Children)
for(state_i in seq(1, state_n)){
  state_entry <- temp$Children[[2]]$Children[[state_i]]
  counties_n  <- length(state_entry$Children)
  for(county_i in seq(1, counties_n)){
    county_entry <- state_entry$Children[[county_i]]
    entries_n    <- length(county_entry$Children)
    for(entry_i in seq(1, entries_n)){
      # Confirm the node we're at is a soil entry
      if('Models.Soils.Soil, Models' == county_entry$Children[[entry_i]]$`$type`){
        # print(c(state_i, county_i, entry_i))
        soils_list[length(soils_list)+1] <- list(county_entry$Children[[entry_i]])
      }      
    }
  }
}
```




# Make a lookup df with metadata and constrain to contiguous US
```{r}
soils_df <- do.call(rbind, 
                    purrr::map(soils_list, function(e){
                      data.frame(
                        State = e$State,
                        Region = e$Region,
                        Longitude = e$Longitude,
                        Latitude = e$Latitude,
                        SoilType = e$SoilType,
                        ApsoilNumber = e$ApsoilNumber,
                        Comments = e$Comments,
                        Name = e$Name
                        )  
                    })) 

soils_df['soils_list_i'] <- seq(1, nrow(soils_df))

# Constrain to contiguous us
soils_df <- soils_df |> filter(!(State %in% c('Alaska', 'Hawaii')))

soils_df[((soils_df$Longitude == 0) | (is.na(soils_df$Longitude)) &
           ((soils_df$Latitude == 0) | (is.na(soils_df$Latitude)))), c('Longitude', 'Latitude')] <- NA

soils_df |> 
  mutate(MissingGPS = case_when(is.na(Longitude) ~ 'NoGPS',
                                !is.na(Longitude) ~ 'GPS')) |>
  mutate(Longitude = case_when(is.na(Longitude) ~ 0, !is.na(Longitude) ~ Longitude), 
         Latitude = case_when(is.na(Latitude) ~ 0, !is.na(Latitude) ~ Latitude)) |>
  ggplot(aes(Longitude, Latitude))+
  geom_point()+
  facet_wrap(~MissingGPS, scales='free' )+
  labs(title = 'Note that some regional soils have no lon/lat')
```



```{r}
# these soils are failing to run. I'm not removing them so that the ordering stays consistent with the files I've already run but I will prevent them from matching with any queries by setting there lon/lat to NA

# I found these by stepping through all soils in the soil_list and trying to run a basic model.
mask <- soils_df$soils_list_i %in% c(139, 150, 159, 170, 174, 184, 186, 235, 250, 252, 258, 263, 268, 283, 285, 320)
soils_df[mask, c('Longitude', 'Latitude')] <- NA
```


## Small scale test
Using the factorial experiment file `SimulateFactorial_Tiny.apsimx` which contains only two cultivars, confirm that that I can change the necessary soil and weather inputs. 

```{r}
# get weather and soil data
# cache_path
# 
# factorial_file = 'SimulateFactorial_Tiny.apsimx'
# 
# ith_lon = -86.52960
# ith_lat = 34.72952
# ith_year_start = '1984'
# ith_year_end = '2022'
# ith_year_end
# ith_planting_date = '1-Apr'
# ith_cultivar = 'A_80'
# ith_base_file = "SimulateBasic_-90_34.apsimx"
# 
# # Download the needed data
# run_apsimx_for_gps(
#     lon = ith_lon,
#     lat = ith_lat,
#     year_start = ith_year_start,
#     year_end = ith_year_end,
#     met_dir = paste0(cache_path, 'power/'),
#     ssurgo_dir = paste0(cache_path, 'ssurgo/'),
#     planting_date = '1-Apr',
#     cultivar = 'A_80',
#     base_file = "SimulateBasic_-90_34.apsimx",
#     src.dir = cache_path,
#     only_dl_data = TRUE
#   )
```


```{r get dist relative to valid soils}
library(geodist)
# take in a lon/lat find closest entry. Will not be useful for the entries at 0,0
calc_dist_vs_soil_df <- function(
    ith_lon,
    ith_lat
    ){
  dists <- geodist(
    rbind(data.frame(
      Longitude = ith_lon,
      Latitude = ith_lat),
      soils_df[, c('Longitude', 'Latitude')]), 
          measure = "geodesic")
  # in meters
  return(dists[1, 2:ncol(dists)])
}
```


```{r}
# Unfortunately there are not matching "Name" entries nor are comments setup in similar ways. Due to this I'm going to use distance to set up the pairings. Because I can't match entries by these varaibles I'm usign location which 
closest_soils_list_entry <- function(ith_lon,
                                     ith_lat){
  
  metadata <- data.frame(Longitude = ith_lon,
                         Latitude = ith_lat)
  # look at distance
  soils_df['temp_dist'] <- calc_dist_vs_soil_df(
    ith_lon = metadata[1, 'Longitude'],
    ith_lat = metadata[1, 'Latitude']
  )
  return(soils_df[which.min(soils_df$temp_dist), 'soils_list_i'])
}
```


```{r}
# given a json file (so it need not be read in over and over again), and desired soil, write out with the desired soil 
replace_soil_in_json <- function(
  input_json_file = jsonlite::read_json(paste0(cache_path, 'SimulateFactorial_Tiny.apsimx')),
  replacement_soil = soils_list[[1]],
  input_file_type = 'basic', # 'factorial'
  output_dir = cache_path
  ){
  if(input_file_type == 'basic'){
    # replacement should be of type "Models.Soils.Soil, Models"
    if(input_json_file$Children[[2]]$Children[[5]]$Children[[2]]$`$type` != "Models.Soils.Soil, Models"){
      print('Input not of basic apsimx format. Has the soils module been moved?')
    } else {
      input_json_file$Children[[2]]$Children[[5]]$Children[[2]] <- replacement_soil
    }
  }
  
  if(input_file_type == 'factorial'){
    # replacement should be of type "Models.Soils.Soil, Models"
    if(input_json_file$Children[[2]]$Children[[1]]$Children[[2]]$Children[[5]]$Children[[2]]$`$type` != "Models.Soils.Soil, Models"){
      print('Input not of basic apsimx format. Has the soils module been moved?')
    } else {
      input_json_file$Children[[2]]$Children[[1]]$Children[[2]]$Children[[5]]$Children[[2]] <- replacement_soil
    }
  }
  
  jsonlite::write_json(input_json_file, 
                       paste0(output_dir, 'temp.apsimx'), 
                       pretty = TRUE, 
                       digits = NA, auto_unbox = TRUE, null = "null", 
                       na = "null")
}
```

```{r}
# # Demo
# ith_lon = -86.52960
# ith_lat = 34.72952
# 
# # From lon/lat get the closest soil
# 
# soils_i <- closest_soils_list_entry(ith_lon = ith_lon, ith_lat = ith_lon)
# soils_df[soils_i, ]
# soils_list[[soils_i]]
# 
# # make a temp.apsimx with the desired soil
# # basic version
# replace_soil_in_json(
#   input_json_file = jsonlite::read_json(paste0(cache_path, 'SimulateBasic_-90_34.apsimx')),
#   replacement_soil = soils_list[[1]],
#   input_file_type = 'basic', # 'factorial'
#   output_dir = cache_path
#   )
# 
# unlink(paste0(cache_path, 'temp.apsimx'))
# 
# # factorial version
# replace_soil_in_json(
#   input_json_file = jsonlite::read_json(paste0(cache_path, 'SimulateFactorial_Tiny.apsimx')),
#   replacement_soil = soils_list[[1]],
#   input_file_type = 'factorial', # 'basic'
#   output_dir = cache_path
#   )
# 
# unlink(paste0(cache_path, 'temp.apsimx'))
```


```{r}
# Warning! needs soils_list, soils_df in global scope
modify_and_run_apsimx_temp <- function(
    ith_lon = -86.52960,
    ith_lat = 34.72952,
    cache_path = "../data/00.06_apsimx_sim_factorial_gps_grid/",
    factorial_file = 'SimulateFactorial_Tiny.apsimx',  
    input_file_type = 'factorial', # 'basic'
    soils_i = 1,
    ith_year_start = '1984',
    ith_year_end = '2022'
){
  # Setup ----
  # set up some state variables so that the simulation is run only if the needed inputs are available.
  met_data_ready     <- FALSE # Met downloaded?
  met_lines_match    <- FALSE # Exactly one line in the apsimx file to update?
  
  # get weather and soil data
  try(
    run_apsimx_for_gps(
      lon = ith_lon,
      lat = ith_lat,
      year_start = ith_year_start,
      year_end = ith_year_end,
      met_dir = paste0(cache_path, 'power/'),
      ssurgo_dir = paste0(cache_path, 'ssurgo/'),
      planting_date = '1-Apr',
      cultivar = 'A_80',
      base_file = "SimulateBasic_-90_34.apsimx",
      src.dir = cache_path,
      only_dl_data = TRUE
    )
  )
  
  # Work with Soil Data ----
  replace_soil_in_json(
    input_json_file = jsonlite::read_json(paste0(cache_path, factorial_file)),
    replacement_soil = soils_list[[soils_i]],
    input_file_type = input_file_type,
    output_dir = cache_path
  )  
  
  # Work with Weather Data ----
  ith_met_path <- paste0(cache_path, 
                         'power/', 
                         paste0(as.character(ith_lon),'_', 
                                as.character(ith_lat),'_', 
                                as.character(ith_year_start),'-', 
                                as.character('01-01'),'_', 
                                as.character(ith_year_end),'-', 
                                as.character('12-31'),
                                '.met'))
  
  met_data_ready <- file.exists(ith_met_path)
  if(met_data_ready){
    
    factorial_file_text <- read_file(paste0(cache_path, 'temp.apsimx'))
    factorial_file_text <- unlist(str_split(factorial_file_text, '\\n'))
    
    ith_met_path <- str_split(ith_met_path, pattern = '/')[[1]]
    replace_met <- ith_met_path[length(ith_met_path)]
    
    # Now I'll pull out the met file name instead of passing it in.
    ith_expect_met <- factorial_file_text[str_detect(
      string = factorial_file_text, '"FileName":.+\\.met')]
    ith_expect_met <- str_extract(ith_expect_met, '[\\w-.]+\\.met')
    
    mask <- str_detect(string = factorial_file_text, ith_expect_met)
    relevant_line <- factorial_file_text[mask]
    
    met_lines_match <- (length(relevant_line) == 1)
    if(met_lines_match){
      replacement_line <- str_replace(relevant_line, pattern = ith_expect_met, replacement = replace_met)
      factorial_file_text[mask] <- replacement_line
      factorial_file_text <- paste(factorial_file_text, collapse = '\n')
      write_file(factorial_file_text, 
                 paste0(cache_path, 'temp.apsimx'))  
    }
  }
  
  # If the tests pass, then run the file ----
  if((met_data_ready & 
      met_lines_match)){
    
    res <- apsimx(
      file = 'temp.apsimx',
      src.dir = cache_path,
      value = "report")
    
  }  else {
    res = data.frame()
  }
  # if there was an issue, return an empty df
  if(nrow(res) == 0){
    res <- data.frame(
      CheckpointID = NA, SimulationID = NA, Experiment = NA, FolderName = NA, 
      SowDate = NA, Genotype = NA, Zone = NA, Clock.Today = NA, 
      Maize.AboveGround.Wt = NA, Maize.LAI = NA, yield_Kgha = NA, Date = NA
    )
  # and also copy the file so that I can audit it and figure out why it did not work.
    ensure_dir_path_exists(paste0(cache_path, 'apsimx_audits/'))
    file.copy(paste0(cache_path, 'temp.apsimx'),
              paste0(cache_path, 'apsimx_audits/',  paste(c(ith_lon, ith_lat, ith_year_start, ith_year_end, soils_i, 'temp.apsimx'), collapse = '__' )))
  }
  
  # delete the temp files
  if('temp.apsimx' %in% list.files(cache_path)){
  unlink(paste0(cache_path, 'temp.apsimx'))    
  }
  if('temp.db' %in% list.files(cache_path)){
  unlink(paste0(cache_path, 'temp.db'))    
  }
  
  return(cbind(data.frame(ith_lon, ith_lat, ith_year_start, ith_year_end, soils_i, factorial_file), res))
}
```


```{r}
# # Demos
# # From lon/lat get the closest soil.
# # This is not included in modify_and_run_apsimx_temp so that the wrapper function below can include it in the expected name.
# soils_i <- closest_soils_list_entry(ith_lon = -86.52960,
#                                     ith_lat = 34.72952)
# 
# modify_and_run_apsimx_temp(
#     ith_lon = -86.52960,
#     ith_lat = 34.72952,
#     cache_path = "../data/00.06_apsimx_sim_factorial_gps_grid/",
#     factorial_file = 'SimulateBasic_-90_34.apsimx',
#     input_file_type = 'basic',
#     soils_i = soils_i,
#     ith_year_start = '1984',
#     ith_year_end = '2022'
# )
# 
# modify_and_run_apsimx_temp(
#     ith_lon = -86.52960,
#     ith_lat = 34.72952,
#     cache_path = "../data/00.06_apsimx_sim_factorial_gps_grid/",
#     factorial_file = 'SimulateFactorial_Tiny.apsimx',
#     input_file_type = 'factorial',
#     soils_i = soils_i,
#     ith_year_start = '1984',
#     ith_year_end = '2022'
# )
```


```{r}
# Test all soils


# recheck these:
# 139 150 159 170 174 184 186 235 250 252 258 263 268 283 285 320


# for(i in c(172, 174)){
#   temp_files = list.files("../data/00.06_apsimx_sim_factorial_gps_grid/")
#   for(temp_file in temp_files[str_detect(temp_files, 'temp\\..+')])
#     unlink(paste0("../data/00.06_apsimx_sim_factorial_gps_grid/", temp_file))
#   
#   print(i)
#   modify_and_run_apsimx_temp(
#     ith_lon = -86.52960,
#     ith_lat = 34.72952,
#     cache_path = "../data/00.06_apsimx_sim_factorial_gps_grid/",
#     factorial_file = 'SimulateBasic_-90_34.apsimx',
#     input_file_type = 'basic',
#     soils_i = i,
#     ith_year_start = '1984',
#     ith_year_end = '2022'
#   )
# }


```


```{r}
wrapper_apsimx_factorial_temp <- function(
    ith_lon = -86.52960,
    ith_lat = 34.72952,
    cache_path = "../data/00.06_apsimx_sim_factorial_gps_grid/",
    factorial_file = 'SimulateFactorial_Tiny.apsimx',
    input_file_type = 'factorial',
    soils_i = 1,
    ith_year_start = '1984',
    ith_year_end = '2022',
    save_path = "../data/00.06_apsimx_sim_factorial_gps_grid/factorial_exps/", # This is for the output not the inputs.
    write_or_return_result = 'write'
){
  # Same approach as `run_and_store_apsimx_for_gps` but for a factorial experiment
  ensure_dir_path_exists(cache_path)
  ensure_dir_path_exists(save_path)
  
  save_name <- paste0(c(as.character(ith_lon), 
                        as.character(ith_lat), 
                        as.character(ith_year_start), 
                        as.character(ith_year_end),
                        as.character(soils_i),
                        str_replace(factorial_file, '\\.apsimx$', '')
  ), collapse = '__')
  save_name <- paste0(save_name, '.csv')

  print(save_name)
  if(!file.exists(paste0(save_path,save_name))){
    res <- modify_and_run_apsimx_temp(
      ith_lon = ith_lon,
      ith_lat = ith_lat,
      cache_path = cache_path,
      factorial_file  = factorial_file,
      input_file_type = input_file_type,
      soils_i = soils_i,
      ith_year_start = ith_year_start,
      ith_year_end   = ith_year_end
    )
    
    if (write_or_return_result == 'return'){
      return(res)
    } else {
      write.csv(res, paste0(save_path,save_name))
    }
  }
}
```




```{r}
# # demo
# soils_i <- closest_soils_list_entry(ith_lon = -86.52960,
#                                     ith_lat = 34.72952)
# wrapper_apsimx_factorial_temp(
#     cache_path = "../data/00.06_apsimx_sim_factorial_gps_grid/",
#     save_path = "../data/00.06_apsimx_sim_factorial_gps_grid/factorial_exps/", # This is for the output not the inputs.
#     factorial_file = 'SimulateFactorial_Tiny.apsimx',
#     input_file_type = 'factorial',
#     soils_i = soils_i,
#     ith_lon = -86.52960,
#     ith_lat = 34.72952,
#     ith_year_start = '1984',
#     ith_year_end = '2022'
# )
```


```{r}
# this takes a while to run.
# soils_i <- closest_soils_list_entry(ith_lon = -86.52960,
#                                     ith_lat = 34.72952)
# wrapper_apsimx_factorial_temp(
#     cache_path = "../data/00.06_apsimx_sim_factorial_gps_grid/",
#     save_path = "../data/00.06_apsimx_sim_factorial_gps_grid/factorial_exps/", # This is for the output not the inputs.
#     factorial_file = 'SimulateFactorial.apsimx',
#     input_file_type = 'factorial',
#     soils_i = soils_i,
#     ith_lon = -86.52960,
#     ith_lat = 34.72952,
#     ith_year_start = '1984',
#     ith_year_end = '2022'
# )

# Visualize
# M <- read.csv('../data/00.06_apsimx_sim_factorial_gps_grid/factorial_exps/-86.5296__34.72952__1984__2022__1__SimulateFactorial.csv')
# M <- M %>% as_tibble()
# 
# M['Year'] <- str_extract(M$Date, '\\d+')
# M['DOY'] <- lubridate::ymd(M$Date) - lubridate::ymd(paste0(M$Year, '-01-01'))
# M['SowDOY'] <- lubridate::dmy(paste0(M$SowDate, M$Year)) - lubridate::ymd(paste0(M$Year, '-01-01'))
# 
# M <- M %>% select(Year, DOY, SowDate, SowDOY, Genotype, yield_Kgha)
# M['SowDOY'] <- as.numeric(M$SowDOY)
# 
# 
# unique(M$Genotype) %>% length()
# unique(M$Year) %>% length()
# unique(M$SowDOY) %>% length()
# 
# M %>%
#   filter(Genotype %in% unique(M$Genotype)[1]) %>%
#   ggplot(aes(x = SowDOY, y = yield_Kgha))+
#   geom_point(alpha = 0.3)+
#   geom_smooth(method = lm)+
#   labs(title = paste0('One Genotype, ',
#                       as.character(length(unique(M$SowDOY))), ' Sowing DOYs, ',
#                       as.character(length(unique(M$Year))), ' Years'
#                       ))
# 
# M %>%
#   ggplot(aes(x = SowDOY, y = yield_Kgha, group = Genotype))+
#   geom_smooth(method = lm, se = F)+
#   labs(title = paste0('Showing all ', as.character(length(unique(M$Genotype))), ' Genotypes'))
```

```{r}
# # demo with daily yield measurements
# soils_i <- closest_soils_list_entry(ith_lon = -86.52960,
#                                     ith_lat = 34.72952)
# wrapper_apsimx_factorial_temp(
#     cache_path = "../data/00.06_apsimx_sim_factorial_gps_grid/",
#     save_path = "../data/00.06_apsimx_sim_factorial_gps_grid/factorial_exps/", # This is for the output not the inputs.
#     factorial_file = 'SimulateBasicDaily_-90_34.apsimx',
#     input_file_type = 'basic',
#     soils_i = soils_i,
#     ith_lon = -86.52960,
#     ith_lat = 34.72952,
#     ith_year_start = '1984',
#     ith_year_end = '2022'
# )
# 
# # Visualize
# M <- read.csv('../data/00.06_apsimx_sim_factorial_gps_grid/factorial_exps/-86.5296__34.72952__1984__2022__248__SimulateBasicDaily_-90_34.csv')
# M <- M %>% as_tibble()
# 
# M['Year'] <- str_extract(M$Date, '\\d+')
# M['DOY'] <- lubridate::ymd(M$Date) - lubridate::ymd(paste0(M$Year, '-01-01'))
# 
# M %>%
#   filter(yield_Kgha != 0) %>%
#   ggplot(aes(x = DOY, y = yield_Kgha, group = Year))+
#   geom_line()
```

```{r}
# # demo with daily yield measurements in factorial
# 
# soils_i <- closest_soils_list_entry(ith_lon = -86.52960,
#                                     ith_lat = 34.72952)
# wrapper_apsimx_factorial_temp(
#     cache_path = "../data/00.06_apsimx_sim_factorial_gps_grid/",
#     save_path = "../data/00.06_apsimx_sim_factorial_gps_grid/factorial_exps/", # This is for the output not the inputs.
#     factorial_file = 'SimulateFactorialDaily_-90_34.apsimx',
#     input_file_type = 'factorial',
#     soils_i = soils_i,
#     ith_lon = -86.52960,
#     ith_lat = 34.72952,
#     ith_year_start = '1984',
#     ith_year_end = '2022'
# )
# 
# M <- read.csv('../data/00.06_apsimx_sim_factorial_gps_grid/factorial_exps/-86.5296__34.72952__1984__2022__248__SimulateFactorialDaily_-90_34.csv')
# M <- M %>% as_tibble()
# 
# M['Year'] <- str_extract(M$Date, '\\d+')
# M['DOY'] <- lubridate::ymd(M$Date) - lubridate::ymd(paste0(M$Year, '-01-01'))
# 
# M %>%
#   filter(yield_Kgha != 0) %>%
#   ggplot(aes(x = DOY, y = yield_Kgha, group = interaction(Year, SowDate, Genotype)))+
#   geom_line()
```



# run on all g2f locations

```{r points to use}
# gps <- read.csv('../inst/extdata/gps_coords.csv')
# gps <- gps[!stringr::str_detect(gps[, 'Env'], '^ONH.+'), ]
# gps <- gps[!stringr::str_detect(gps[, 'Env'], '^GEH.+'), ]
# 
# gps <- gps %>% 
#   rename(lat = Latitude_of_Field,
#          lon = Longitude_of_Field) %>% 
#   select(lat, lon) %>% 
#   distinct()
# gps_g2f <- gps
```


```{r}
# tic_outer <- Sys.time()
# tics <- c()
# for(i in seq(1, nrow(gps))){
#   temp_files = list.files("../data/00.06_apsimx_sim_factorial_gps_grid/")
#   for(temp_file in temp_files[str_detect(temp_files, 'temp\\..+')]){
#     unlink(paste0("../data/00.06_apsimx_sim_factorial_gps_grid/", temp_file))
#   }
#   ## all because I don't have tqdm ====
#   tics[length(tics)+1] <- Sys.time()
#   if(length(tics)>1){ 
#     #      # Remaining iter    # Worst case time per iter (and a way to ignore cached results)
#     secs = (nrow(gps)-(i-1)) * max(tics[2:length(tics)]-tics[1])
#     minutes = as.character(secs %/% 60)
#     sec = as.character(round(secs %% 60))
#     print(paste(rep('-', 80), collapse = ''))
#     print(paste0(minutes, ':', if(as.numeric(sec)>=9){sec}else{paste0('0', sec)}))
#     print(paste(rep('-', 80), collapse = ''))
#   }
#   soils_i <- closest_soils_list_entry(ith_lon = gps[i, 'lon'],
#                                       ith_lat = gps[i, 'lat'])
#   try(
#   wrapper_apsimx_factorial_temp(
#       cache_path = "../data/00.06_apsimx_sim_factorial_gps_grid/",
#       save_path = "../data/00.06_apsimx_sim_factorial_gps_grid/factorial_exps/", # This is for the output not the inputs.
#       factorial_file = 'SimulateFactorialDaily.apsimx',
#       input_file_type = 'factorial',
#       soils_i = soils_i,
#       ith_lon = gps[i, 'lon'],
#       ith_lat = gps[i, 'lat'],
#       ith_year_start = '1984',
#       ith_year_end = '2022'
#   )
#   )
# }
# toc_outer <- Sys.time()
# print(toc_outer-tic_outer)
```

## Repeat for grid over usa
### Load GPS Data
```{r}
if(file.exists(paste0(cache_path, 'gps_grid_soil_match.csv'))){
  gps <- read.csv(paste0(cache_path, 'gps_grid_soil_match.csv'))  
}else{
  gps <- read.csv('../data/00.01_setup_USA_env_gps_grid/gps_grid.csv') %>% rename(Latitude = lat, Longitude = lon)
  
  gps['MinKm'] <- -1
  gps['soil_i_or_is'] <- -1
  
  # Would be faster to compute vornoi regions and then check which a coordinate pair fell in but this is fast enough.
  for(i in seq(1, nrow(gps))){
    soil_temp <- soils_df[, c("Longitude", "Latitude")]
    soil_temp[is.na(soil_temp$Longitude), "Longitude"] <- 0
    soil_temp[is.na(soil_temp$Latitude), "Latitude"] <- 0
    
    dists <- geodist(
      rbind(gps[i, c("Longitude", "Latitude")],
            soil_temp[, c("Longitude", "Latitude")]), 
      measure = 'geodesic'
    )
    min_dist <- min(dists[1, 2:ncol(dists)], na.rm = TRUE)
    min_i_or_is <- c(1:(ncol(dists)-1))[dists[1, 2:ncol(dists)] == min_dist]
    min_i_or_is <- paste(as.character(min_i_or_is), collapse = '-')
    
    gps[i, 'MinKm'] <- min_dist/1000
    gps[i, 'soil_i_or_is'] <- min_i_or_is
  }
  write.csv(gps, paste0(cache_path, 'gps_grid_soil_match.csv'))
}

gps %>% 
  ggplot(aes(x = Longitude, y = Latitude, color = MinKm))+
  geom_point()

gps %>% 
  ggplot(aes(x = MinKm))+
  geom_density()

gps %>% 
  ggplot(aes(x = Longitude, y = Latitude, color = MinKm<100))+
  geom_point()

gps %>% 
  ggplot(aes(x = Longitude, y = Latitude, color = soil_i_or_is))+
  geom_point()+
  theme(legend.position = '')



gps %>% filter(MinKm<25) %>% 
  ggplot(aes(x = Longitude, y = Latitude, color = soil_i_or_is))+
  geom_point()+
  theme(legend.position = '')

gps <- gps %>% filter(MinKm<25)
gps_grid <- gps
```

```{r}
# get gps coordinates from g2f and merge into grid
gps <- read.csv('../inst/extdata/gps_coords.csv')
gps <- gps[!stringr::str_detect(gps[, 'Env'], '^ONH.+'), ]
gps <- gps[!stringr::str_detect(gps[, 'Env'], '^GEH.+'), ]

gps <- gps %>% 
  rename(lat = Latitude_of_Field,
         lon = Longitude_of_Field) %>% 
  select(lat, lon) %>% 
  distinct()

# so that this can be merged with the below I'm adding in `soil_i_or_is` here.
gps['soil_i_or_is'] <- -1
for(i in seq(1, nrow(gps))){
  gps[i, 'soil_i_or_is'] <- closest_soils_list_entry(ith_lon = gps[i, 'lon'],
                                                     ith_lat = gps[i, 'lat'])  
}


gps <- gps %>% 
  rename(Longitude = lon,
         Latitude = lat) %>% 
  mutate(soil_i_or_is = as.character(soil_i_or_is))

gps <- full_join(gps, gps_grid)
```



```{r}
# similar to above, but this one uses precomputed soil i (or is)
# tic_outer <- Sys.time()
# tics <- c()
# for(i in seq(1, nrow(gps))){
#   temp_files = list.files("../data/00.06_apsimx_sim_factorial_gps_grid/")
#   for(temp_file in temp_files[str_detect(temp_files, 'temp\\..+')]){
#     unlink(paste0("../data/00.06_apsimx_sim_factorial_gps_grid/", temp_file))
#   }
#   ## all because I don't have tqdm ====
#   tics[length(tics)+1] <- Sys.time()
#   if(length(tics)>1){ 
#     #      # Remaining iter    # Worst case time per iter (and a way to ignore cached results)
#     secs = (nrow(gps)-(i-1)) * max(tics[2:length(tics)]-tics[1])
#     minutes = as.character(secs %/% 60)
#     sec = as.character(round(secs %% 60))
#     print(paste(rep('-', 80), collapse = ''))
#     print(paste0(minutes, ':', if(as.numeric(sec)>=9){sec}else{paste0('0', sec)}))
#     print(paste(rep('-', 80), collapse = ''))
#   }
#   # soils_i <- closest_soils_list_entry(ith_lon = gps[i, 'lon'],
#   #                                     ith_lat = gps[i, 'lat'])
#   
#   soil_i_or_is <- gps[i, 'soil_i_or_is']
#   for(soils_i in unlist(str_split(soil_i_or_is, '-'))){
#     soils_i <- as.numeric(soils_i)
#     try(
#     wrapper_apsimx_factorial_temp(
#       cache_path = "../data/00.06_apsimx_sim_factorial_gps_grid/",
#       save_path = "../data/00.06_apsimx_sim_factorial_gps_grid/factorial_exps/", # This is for the output not the inputs.
#       factorial_file = 'SimulateFactorialDaily.apsimx',
#       input_file_type = 'factorial',
#       soils_i = soils_i,
#       ith_lon = gps[i, 'Longitude'],
#       ith_lat = gps[i, 'Latitude'],
#       ith_year_start = '1984',
#       ith_year_end = '2022'
#     ) 
#     )
#   }
# }
# toc_outer <- Sys.time()
# print(toc_outer-tic_outer)
```

```{r}
saveRDS(soils_list, file = paste0(cache_path, 'soils_df'))
write.csv(soils_df, file = paste0(cache_path, 'soils_df'))
```


```{r}
# similar to above, but this one uses precomputed soil i (or is)
tic_outer <- Sys.time()
tics <- c()
for(i in seq(1, nrow(gps))){
  temp_files = list.files("../data/00.06_apsimx_sim_factorial_gps_grid/")
  for(temp_file in temp_files[str_detect(temp_files, 'temp\\..+')]){
    unlink(paste0("../data/00.06_apsimx_sim_factorial_gps_grid/", temp_file))
  }
  ## all because I don't have tqdm ====
  tics[length(tics)+1] <- Sys.time()
  if(length(tics)>1){
    #      # Remaining iter    # Worst case time per iter (and a way to ignore cached results)
    secs = (nrow(gps)-(i-1)) * max(tics[2:length(tics)]-tics[1])
    minutes = as.character(secs %/% 60)
    sec = as.character(round(secs %% 60))
    print(paste(rep('-', 80), collapse = ''))
    print(paste0(minutes, ':', if(as.numeric(sec)>=9){sec}else{paste0('0', sec)}))
    print(paste(rep('-', 80), collapse = ''))
  }
  # soils_i <- closest_soils_list_entry(ith_lon = gps[i, 'lon'],
  #                                     ith_lat = gps[i, 'lat'])
  
  soil_i_or_is <- gps[i, 'soil_i_or_is']
  for(soils_i in unlist(str_split(soil_i_or_is, '-'))){
    soils_i <- as.numeric(soils_i)
    
    # try(
    #   wrapper_apsimx_factorial_temp(
    #     cache_path = "../data/00.06_apsimx_sim_factorial_gps_grid/",
    #     save_path = "../data/00.06_apsimx_sim_factorial_gps_grid/factorial_exps/", # This is for the output not the inputs.
    #     factorial_file = 'SimulateFactorialDaily.apsimx',
    #     input_file_type = 'factorial',
    #     soils_i = soils_i,
    #     ith_lon = gps[i, 'Longitude'],
    #     ith_lat = gps[i, 'Latitude'],
    #     ith_year_start = '1984',
    #     ith_year_end = '2022',
    #     write_or_return_result = 'write'
    # )
    
    
    # check if the result is already in the database
    
    db_path <- paste0(cache_path, 'factorial_exps/default_cultivar.sqlite')
    if(!file.exists(db_path)){
      # pass - no database
    } else {
      mydb <- dbConnect(RSQLite::SQLite(), db_path)
      if(!(DBI::dbExistsTable(mydb, 'Ids'))){
        # pass - no data
      } else {
        stored_ids <- dbReadTable(mydb, 'Ids')
      }
      dbDisconnect(mydb)
    }
    
    stored_ids |> head()
    
    
    in_db <- ((soils_i %in% stored_ids$SoilIdx) & 
                (gps[i, 'Longitude'] %in% stored_ids$Longitude) &
                (gps[i, 'Latitude'] %in% stored_ids$Latitude))
    
    ## Try to run the model if there is not an entry for it. ===================
    if(!in_db){
      # print(i)
      # break
      res <- NA
      try(
        res <- wrapper_apsimx_factorial_temp(
          cache_path = "../data/00.06_apsimx_sim_factorial_gps_grid/",
          save_path = "../data/00.06_apsimx_sim_factorial_gps_grid/factorial_exps/", # This is for the output not the inputs.
          factorial_file = 'SimulateFactorialDaily.apsimx',
          input_file_type = 'factorial',
          soils_i = soils_i,
          ith_lon = gps[i, 'Longitude'],
          ith_lat = gps[i, 'Latitude'],
          ith_year_start = '1984',
          ith_year_end = '2022',
          write_or_return_result = 'return'
        )
      )
      ## Reduce the dataset size and add to database. ==========================
      if(!(typeof(res) == 'NULL')){
        M <- res
        # Drop columns that aren't needed
        res_select <- M[, c(
          # Indepenent Variables
          'ith_lon', 'ith_lat', 'soils_i', 'SowDate', 'Genotype', 'Date',
          # Dependent Variables
          'Maize.AboveGround.Wt', 'Maize.LAI', 'yield_Kgha'
        )] |> 
          rename(Longitude = ith_lon, Latitude = ith_lat, SoilIdx = soils_i)
        
        M <- res_select
        # Drop rows without data
        
        # can get a tiny performance benefit from looking at the sum vs 0 instead of looking at each col. 
        mask <- (M$Maize.AboveGround.Wt + M$Maize.LAI + M$Maize.AboveGround.Wt) == 0
        M <- M[!mask, ]
        # reduce down the genotype name's size
        M$Genotype <- str_replace(M$Genotype, '.+ = ', '')
        
        # Split up tables
        ## Attributes ====
        res_ids <- M |> select(-Maize.AboveGround.Wt, -Maize.LAI, -yield_Kgha, -Date) |> distinct()
        # add a uid col
        res_ids['FactorialUID'] = NA
        # need to look at database to find lowest unused uid.
      
        lowest_uid <- 0
        # replace if there's pre-recorded data.
        db_path <- paste0(cache_path, 'factorial_exps/default_cultivar.sqlite')
        if(!file.exists(db_path)){
          # pass - no database
        } else {
          mydb <- dbConnect(RSQLite::SQLite(), db_path)
          if(!(DBI::dbExistsTable(mydb, 'Ids'))){
            # pass - no data
          } else {
            stored_ids <- dbReadTable(mydb, 'Ids')
            dbDisconnect(mydb)
            # check that there are no matching factorial combinations in the database
            res_ids <- left_join(res_ids, stored_ids)
            # don't allow updating by default.
            res_ids <- res_ids[is.na(res_ids$FactorialUID), ]
            lowest_uid <- max(stored_ids$FactorialUID)
          }
        }
        # add new uids
        res_ids['FactorialUID'] <- lowest_uid + seq(1, nrow(res_ids['FactorialUID']))
        res_ids$FactorialUID <- as.integer(res_ids$FactorialUID)
        
        ## Datasets ====
        res_dvs <- left_join(distinct(M), res_ids) |> 
          select(-Longitude, -Latitude, -SoilIdx, -SowDate, -Genotype)
        # convert to date
        res_dvs$Date <- as.numeric(lubridate::as_date(res_dvs$Date))
        # now these tables are ready to insert. Could be further reduced by having a unique table for each genotype.
        
        mydb <- dbConnect(RSQLite::SQLite(),db_path)
        dbWriteTable(mydb, 'Ids', res_ids, append = TRUE)
        dbWriteTable(mydb, 'Results', res_dvs, append = TRUE)
        dbDisconnect(mydb)
      }
    }
    # if there was a result, clean output, split into tables and send to database
  }
}
toc_outer <- Sys.time()
print(toc_outer-tic_outer)
```

```{r}

```

